import time
from datetime import datetime, timedelta 
from fastapi import FastAPI, HTTPException, Depends, status, BackgroundTasks, UploadFile, File
from fastapi.security import OAuth2PasswordRequestForm
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy import desc
import os
import uvicorn
import io
import pandas as pd
from pathlib import Path

# AI & LangChain
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain.schema import Document
from github import Github

from dotenv import load_dotenv

# Import à¹„à¸Ÿà¸¥à¹Œà¸£à¸°à¸šà¸š
from .database import Base, engine
from .auth import get_db, create_access_token, get_current_user, get_password_hash, User as UserModel, ChatHistory

# à¹‚à¸«à¸¥à¸” ENV
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# --- à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡à¹ƒà¸™ Database ---
Base.metadata.create_all(bind=engine)

# --- Config ---
INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "docscarmencloud")

# --- à¹‚à¸«à¸¥à¸”à¸ªà¸¡à¸­à¸‡ AI ---
print("ğŸ§  Loading AI Brain...")
try:
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)
    llm = ChatGoogleGenerativeAI(model="gemma-3-27b-it", temperature=0.3)
    
    prompt_template = """
    Role: You are "Carmen" (à¸„à¸²à¸£à¹Œà¹€à¸¡à¸™), a professional and gentle AI Assistant for Carmen Software.
    
    Instructions:
    1. Answer the question based ONLY on the provided context.
    2. **Tone:** Be polite, helpful, and professional.
    3. **Language Rules:**
       - If the user asks in **Thai**: Answer in **Thai** and MUST use female polite particles (e.g., à¸„à¹ˆà¸°, à¸„à¸°, à¸™à¸°à¸„à¸°).
       - If the user asks in **English** or explicitly requests English: Answer in **English**.
    
    Context Information:
    {context}
    
    User Question: {question}
    
    Answer:
    """
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
except Exception as e:
    print(f"âŒ AI Init Error: {e}")
    vectorstore = None
    llm = None

# --- Setup FastAPI ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ğŸ” Login API ---
@app.post("/token")
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    user = db.query(UserModel).filter(UserModel.username == form_data.username).first()
    
    from passlib.context import CryptContext
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
    
    if not user or not pwd_context.verify(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer", "client_namespace": user.client_id}

# --- ğŸ“œ API à¸”à¸¶à¸‡à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¹à¸Šà¸— ---
@app.get("/chat/history")
async def get_chat_history(
    current_user: UserModel = Depends(get_current_user), 
    db: Session = Depends(get_db)
):
    history = db.query(ChatHistory).filter(ChatHistory.user_id == current_user.id)\
                .order_by(desc(ChatHistory.timestamp))\
                .limit(50).all()
    return history[::-1] 

# --- ğŸ’¬ Chat API ---
class Question(BaseModel):
    text: str

@app.post("/chat")
async def chat_endpoint(
    question: Question, 
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not vectorstore: raise HTTPException(status_code=500, detail="AI Not Ready")
    
    try:
        user_message = question.text
        
        # Save User Msg
        user_msg_db = ChatHistory(user_id=current_user.id, sender="user", message=user_message)
        db.add(user_msg_db)
        db.commit()
        
        # --- Logic AI ---
        client_ns = current_user.client_id 
        docs_private = []
        if client_ns and client_ns != "global":
            docs_private = vectorstore.similarity_search(user_message, k=2, namespace=client_ns)
        
        # à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™ Global Namespace à¸”à¹‰à¸§à¸¢
        docs_common = vectorstore.similarity_search(user_message, k=2, namespace="global") 
        all_docs = docs_private + docs_common

        if not all_docs:
            bot_ans = "à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸—à¸±à¹‰à¸‡à¹ƒà¸™à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸·à¹‰à¸™à¸à¸²à¸™à¸„à¹ˆà¸°"
        else:
            chain = PROMPT | llm | StrOutputParser()
            context_text = "\n\n".join([d.page_content for d in all_docs])
            bot_ans = chain.invoke({"context": context_text, "question": user_message})

        # Save Bot Msg
        bot_msg_db = ChatHistory(user_id=current_user.id, sender="bot", message=bot_ans)
        db.add(bot_msg_db)
        db.commit() 
        db.refresh(bot_msg_db) 

        return {
            "answer": bot_ans, 
            "message_id": bot_msg_db.id 
        }

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- ğŸ‘ Feedback API ---
class FeedbackRequest(BaseModel):
    score: int 

@app.post("/chat/feedback/{message_id}")
async def feedback_endpoint(
    message_id: int,
    feedback: FeedbackRequest,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    msg = db.query(ChatHistory).filter(ChatHistory.id == message_id).first()
    
    if not msg:
        raise HTTPException(status_code=404, detail="Message not found")
        
    if msg.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not your message")

    msg.feedback = feedback.score
    db.commit()
    return {"status": "success", "score": feedback.score}

# ==========================================
# ğŸ§  Training APIs (Manual, Upload, GitHub)
# ==========================================

# 1. Manual Input
class TrainingRequest(BaseModel):
    text: str
    namespace: str = "global"  # âœ… à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ default à¹€à¸›à¹‡à¸™ global
    source: str = "admin_manual"

@app.post("/train")
async def train_data(
    request: TrainingRequest,
    current_user: UserModel = Depends(get_current_user), 
    db: Session = Depends(get_db)
):
    if current_user.client_id != "global" and request.namespace != current_user.client_id:
         raise HTTPException(status_code=403, detail="à¸„à¸¸à¸“à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¹Œà¸ªà¸­à¸™à¹ƒà¸™à¸«à¸±à¸§à¸‚à¹‰à¸­à¸™à¸µà¹‰")

    if not vectorstore:
        raise HTTPException(status_code=500, detail="à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Pinecone à¹„à¸¡à¹ˆà¹„à¸”à¹‰")

    try:
        print(f"ğŸ§  Learning: {request.text[:50]}... -> Namespace: {request.namespace}")
        
        vectorstore.add_texts(
            texts=[request.text],
            metadatas=[{
                "source": request.source,
                "added_by": current_user.username,
                "timestamp": str(datetime.now())
            }],
            namespace=request.namespace
        )
        return {"status": "success", "message": "à¸ˆà¸³à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸°! ğŸ’¾"}

    except Exception as e:
        print(f"Training Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# 2. File Upload
@app.post("/train/upload")
async def train_upload(
    file: UploadFile = File(...),
    namespace: str = "global", # âœ… à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ default à¹€à¸›à¹‡à¸™ global
    source: str = "File Upload",
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if current_user.client_id != "global" and namespace != current_user.client_id:
        raise HTTPException(status_code=403, detail="à¸„à¸¸à¸“à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¹Œà¸ªà¸­à¸™à¹ƒà¸™à¸«à¸±à¸§à¸‚à¹‰à¸­à¸™à¸µà¹‰")
    
    if not vectorstore:
        raise HTTPException(status_code=500, detail="à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Pinecone à¹„à¸¡à¹ˆà¹„à¸”à¹‰")

    text_content = ""
    filename = file.filename.lower()

    try:
        contents = await file.read()
        
        if filename.endswith(".pdf"):
            from pypdf import PdfReader
            pdf_file = io.BytesIO(contents)
            reader = PdfReader(pdf_file)
            for page in reader.pages:
                text_content += page.extract_text() + "\n"
                
        elif filename.endswith(".csv"):
            df = pd.read_csv(io.BytesIO(contents))
            text_content = df.to_string(index=False)
            
        elif filename.endswith((".txt", ".md", ".py", ".js", ".html", ".css", ".json")):
            text_content = contents.decode("utf-8")
            
        else:
            raise HTTPException(status_code=400, detail="à¸£à¸­à¸‡à¸£à¸±à¸šà¹€à¸‰à¸à¸²à¸° PDF, CSV, à¹à¸¥à¸° Text/Code Files à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text(text_content)
        
        print(f"ğŸ“„ File: {filename} -> {len(chunks)} Chunks")

        vectorstore.add_texts(
            texts=chunks,
            metadatas=[{
                "source": f"{source} ({filename})",
                "added_by": current_user.username,
                "timestamp": str(datetime.now())
            } for _ in chunks],
            namespace=namespace
        )

        return {"status": "success", "message": f"à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ {filename} à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! ({len(chunks)} à¸ªà¹ˆà¸§à¸™)"}

    except Exception as e:
        print(f"Upload Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# 3. GitHub Logic

def get_modified_files(repo, days=30):
    """à¸«à¸²à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¹ƒà¸™ X à¸§à¸±à¸™à¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™à¸¡à¸²"""
    print(f"ğŸ•µï¸â€â™‚ï¸ Checking for updates in the last {days} days...")
    since_date = datetime.now() - timedelta(days=days)
    
    modified_files = set()
    try:
        # à¸”à¸¶à¸‡ Commit à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡
        commits = repo.get_commits(since=since_date)
        
        for commit in commits:
            for file in commit.files:
                # à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸à¸²à¸°à¹„à¸Ÿà¸¥à¹Œà¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š
                if file.filename.endswith((".md", ".mdx", ".txt", ".csv", ".py", ".js", ".ts", ".html", ".css", ".json")):
                    modified_files.add(file.filename)
                    
        print(f"   âœ¨ Found {len(modified_files)} modified files.")
        return list(modified_files)
    except Exception as e:
        print(f"   âŒ Error getting commits: {e}")
        return []

def get_file_content(repo, file_path):
    """à¹‚à¸«à¸¥à¸”à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸µà¸¢à¸§ (à¸£à¸°à¸šà¸¸ Path)"""
    try:
        file_content = repo.get_contents(file_path)
        return Document(
            page_content=file_content.decoded_content.decode("utf-8"),
            metadata={"source": file_content.html_url, "file_path": file_path}
        )
    except Exception as e:
        print(f"   âš ï¸ Error reading {file_path}: {e}")
        return None

def get_github_docs(repo_name, access_token):
    print(f"ğŸ•µï¸â€â™‚ï¸ Connecting to GitHub Repo: '{repo_name}'")
    
    # Clean Inputs
    repo_name = repo_name.strip()
    access_token = access_token.strip() if access_token else None
    
    docs = []
    try:
        # 1. à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ GitHub
        if access_token:
            print("   ğŸ”‘ Using Access Token")
            g = Github(access_token)
        else:
            print("   ğŸŒ Using Anonymous Access (Public Repo Only)")
            g = Github()

        # 2. à¸„à¹‰à¸™à¸«à¸² Repo
        repo = g.get_repo(repo_name)
        print(f"   âœ… Found Repo: {repo.full_name} (Default Branch: {repo.default_branch})")

        # 3. à¸”à¸¶à¸‡à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (Recursive)
        contents = repo.get_contents("")
        file_count = 0
        
        while contents:
            file_content = contents.pop(0)
            
            if file_content.type == "dir":
                contents.extend(repo.get_contents(file_content.path))
            else:
                # âœ… à¹€à¸à¸´à¹ˆà¸¡à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š (Code, Text, Config)
                ALLOWED_EXTENSIONS = (
                    ".md", ".mdx", ".txt", ".csv", 
                    ".py", ".js", ".ts", ".html", ".css", ".json"
                )
                
                if file_content.path.endswith(ALLOWED_EXTENSIONS):
                    file_count += 1
                    try:
                        # Decode à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹„à¸Ÿà¸¥à¹Œ
                        decoded_content = file_content.decoded_content.decode("utf-8")
                        
                        docs.append(Document(
                            page_content=decoded_content,
                            metadata={
                                "source": file_content.html_url,
                                "file_path": file_content.path
                            }
                        ))
                        # print(f"     ğŸ“„ Loaded: {file_content.path}") # à¸›à¸´à¸”à¹„à¸§à¹‰à¸ˆà¸°à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸£à¸ Log
                    except Exception as decode_err:
                        print(f"     âš ï¸ Skip {file_content.path}: {decode_err}")

        print(f"   ğŸ“Š Summary: Found {file_count} valid files in repo.")
        return docs

    except Exception as e:
        # ğŸš¨ à¹à¸ˆà¹‰à¸‡ Error à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
        print(f"âŒ GitHub Error Detail: {type(e).__name__} - {str(e)}")
        
        # à¸à¸£à¸“à¸µ 404 (à¸«à¸²à¹„à¸¡à¹ˆà¹€à¸ˆà¸­)
        if "404" in str(e):
             print("   ğŸ‘‰ à¸„à¸³à¹à¸™à¸°à¸™à¸³: à¹€à¸Šà¹‡à¸„à¸Šà¸·à¹ˆà¸­ Repo à¹ƒà¸«à¹‰à¸–à¸¹à¸ à¸«à¸£à¸·à¸­à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ Private Repo à¸•à¹‰à¸­à¸‡à¹ƒà¸ªà¹ˆ Token")
        
        # à¸à¸£à¸“à¸µ 401 (à¸£à¸«à¸±à¸ªà¸œà¸´à¸”)
        if "401" in str(e) or "Bad credentials" in str(e):
             print("   ğŸ‘‰ à¸„à¸³à¹à¸™à¸°à¸™à¸³: Token à¸œà¸´à¸” à¸«à¸£à¸·à¸­à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸")

        return []
    
training_state = {
    "is_running": False,
    "progress": 0,          # %
    "total_chunks": 0,
    "processed_chunks": 0,
    "status": "Idle",
    "logs": [],             # à¹€à¸à¹‡à¸š Log à¸¢à¹‰à¸­à¸™à¸«à¸¥à¸±à¸‡ 10 à¸šà¸£à¸£à¸—à¸±à¸”
    "start_time": 0,
    "estimated_remaining": 0,# à¸§à¸´à¸™à¸²à¸—à¸µ
    "abort": False
}    
    
def add_log(message: str):
    """à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸Šà¹ˆà¸§à¸¢à¹€à¸à¹‡à¸š Log à¹à¸¥à¸° Print à¸¥à¸‡ Console"""
    print(message)
    timestamp = datetime.now().strftime("%H:%M:%S")
    training_state["logs"].append(f"[{timestamp}] {message}")
    # à¹€à¸à¹‡à¸šà¹à¸„à¹ˆ 20 à¸šà¸£à¸£à¸—à¸±à¸”à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸à¸­ (à¹€à¸”à¸µà¹‹à¸¢à¸§ Memory à¹€à¸•à¹‡à¸¡)
    if len(training_state["logs"]) > 20:
        training_state["logs"].pop(0)    

def process_github_training(repo_name: str, token: str, namespace: str, user_name: str, incremental: bool = False):
    global training_state
    
    # Reset State
    training_state.update({
        "is_running": True,
        "progress": 0,
        "total_chunks": 0,
        "processed_chunks": 0,
        "status": "Starting",
        "logs": [],
        "start_time": time.time(),
        "estimated_remaining": 0,
        "abort": False  # âœ… 1. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸˜à¸‡à¸¢à¸à¹€à¸¥à¸´à¸
    })

    try:
        add_log(f"ğŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ GitHub Repo: {repo_name}")
        if incremental:
            add_log(f"ğŸ”„ Mode: Incremental Update (à¸­à¸±à¸›à¹€à¸”à¸•à¹€à¸‰à¸à¸²à¸°à¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹ƒà¸™ 30 à¸§à¸±à¸™)")
        else:
            add_log(f"ğŸ’¿ Mode: Full Load (à¹‚à¸«à¸¥à¸”à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)")

        # 1. à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ GitHub
        if token: g = Github(token)
        else: g = Github()
        repo = g.get_repo(repo_name)

        docs = []
        
        # âœ… à¹à¸¢à¸ Logic à¸•à¸²à¸¡à¹‚à¸«à¸¡à¸”
        if incremental:
            # 1.1 à¸«à¸²à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™
            file_paths = get_modified_files(repo, days=30)
            if not file_paths:
                add_log("âœ… à¹„à¸¡à¹ˆà¸à¸šà¸à¸²à¸£à¸­à¸±à¸›à¹€à¸”à¸•à¹ƒà¸«à¸¡à¹ˆà¹† à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡ 30 à¸§à¸±à¸™à¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™à¸¡à¸²")
                training_state["status"] = "Completed"
                training_state["progress"] = 100
                training_state["is_running"] = False
                return
            
            # 1.2 à¹‚à¸«à¸¥à¸”à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸µà¸¥à¸°à¹„à¸Ÿà¸¥à¹Œ
            add_log(f"ğŸ“¥ à¸à¸³à¸¥à¸±à¸‡à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” {len(file_paths)} à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ...")
            for idx, path in enumerate(file_paths):
                # ğŸ›‘ à¹€à¸Šà¹‡à¸„ Cancel à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ (à¹€à¸œà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¹€à¸¢à¸­à¸°)
                if training_state["abort"]:
                    add_log("â›” à¸¢à¸à¹€à¸¥à¸´à¸à¸à¸²à¸£à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”")
                    training_state["status"] = "Cancelled"
                    training_state["is_running"] = False
                    return

                doc = get_file_content(repo, path)
                if doc: docs.append(doc)
        else:
            # 1.1 à¹‚à¸«à¸¥à¸”à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (Logic à¹€à¸”à¸´à¸¡)
            docs = get_github_docs(repo_name, token)

        if not docs:
            add_log("âŒ à¹„à¸¡à¹ˆà¸à¸šà¹€à¸­à¸à¸ªà¸²à¸£à¸—à¸µà¹ˆà¸ˆà¸°à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥")
            training_state["status"] = "Failed"
            training_state["is_running"] = False
            return

        add_log(f"âœ‚ï¸ à¸à¸³à¸¥à¸±à¸‡à¸«à¸±à¹ˆà¸™à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸ˆà¸²à¸ {len(docs)} à¹„à¸Ÿà¸¥à¹Œ...")
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(docs)
        
        total_chunks = len(chunks)
        training_state["total_chunks"] = total_chunks
        add_log(f"ğŸ“¦ à¹€à¸•à¸£à¸µà¸¢à¸¡à¸ªà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {total_chunks} à¸Šà¸´à¹‰à¸™ (Chunks)")

        for chunk in chunks:
            chunk.metadata["added_by"] = user_name
            chunk.metadata["timestamp"] = str(datetime.now())
            chunk.metadata["source_type"] = "github_repo"

        batch_size = 30  
        sleep_time = 20  
        
        for i in range(0, total_chunks, batch_size):
            # ğŸ›‘ 2. à¹€à¸Šà¹‡à¸„à¸˜à¸‡à¹à¸”à¸‡ à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡à¹à¸•à¹ˆà¸¥à¸° Batch
            if training_state["abort"]:
                add_log("â›” à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£à¸–à¸¹à¸à¸¢à¸à¹€à¸¥à¸´à¸à¹‚à¸”à¸¢ Admin")
                training_state["status"] = "Cancelled"
                training_state["is_running"] = False
                return # à¸ˆà¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸±à¸™à¸—à¸µ
            
            # à¸„à¸³à¸™à¸§à¸“à¹€à¸§à¸¥à¸²
            current_time = time.time()
            elapsed_time = current_time - training_state["start_time"]
            processed = i
            if processed > 0:
                speed = processed / elapsed_time
                remaining_chunks = total_chunks - processed
                eta = remaining_chunks / speed if speed > 0 else 0
                training_state["estimated_remaining"] = int(eta)
            
            percent = int((i / total_chunks) * 100)
            training_state["progress"] = percent
            training_state["processed_chunks"] = i
            training_state["status"] = "Processing"
            
            add_log(f"ğŸ“¤ à¸à¸³à¸¥à¸±à¸‡à¸ªà¹ˆà¸‡ Batch {(i//batch_size)+1} (Process: {i}/{total_chunks}) - ETA: {int(training_state['estimated_remaining'])}s")

            batch = chunks[i : i + batch_size]
            vectorstore.add_documents(documents=batch, namespace=namespace)
            
            add_log(f"âœ… Batch {(i//batch_size)+1} à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! à¸à¸±à¸à¸«à¸²à¸¢à¹ƒà¸ˆ {sleep_time} à¸§à¸´à¸™à¸²à¸—à¸µ...")
            
            # ğŸ›‘ 3. Smart Sleep (à¹€à¸Šà¹‡à¸„ Cancel à¸—à¸¸à¸à¸§à¸´à¸™à¸²à¸—à¸µ à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸à¸±à¸)
            for _ in range(sleep_time):
                if training_state["abort"]: break
                time.sleep(1)
            
        training_state["progress"] = 100
        training_state["status"] = "Completed"
        training_state["is_running"] = False
        add_log(f"ğŸ‰ à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ! à¸­à¸±à¸›à¹€à¸”à¸•à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {total_chunks} à¸Šà¸´à¹‰à¸™à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢")
        
    except Exception as e:
        training_state["status"] = "Error"
        training_state["is_running"] = False
        add_log(f"âš ï¸ Error: {str(e)}")

@app.post("/train/cancel")
async def cancel_training(current_user: UserModel = Depends(get_current_user)):
    global training_state
    if training_state["is_running"]:
        training_state["abort"] = True
        training_state["status"] = "Cancelling..."
        add_log("ğŸ›‘ à¹„à¸”à¹‰à¸£à¸±à¸šà¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸¢à¸à¹€à¸¥à¸´à¸! à¸à¸³à¸¥à¸±à¸‡à¸«à¸¢à¸¸à¸”à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£...")
    return {"status": "success", "message": "Cancellation requested"}        

# âœ… API à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸«à¹‰à¸«à¸™à¹‰à¸²à¹€à¸§à¹‡à¸šà¸¡à¸²à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
@app.get("/train/status")
async def get_training_status():
    return training_state

class GithubRequest(BaseModel):
    repo_name: str
    github_token: str
    namespace: str = "global"
    incremental: bool = False 

@app.post("/train/github")
async def train_github(
    request: GithubRequest,
    background_tasks: BackgroundTasks,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if current_user.client_id != "global" and request.namespace != current_user.client_id:
         raise HTTPException(status_code=403, detail="à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¹Œ")

    background_tasks.add_task(
        process_github_training, 
        request.repo_name, 
        request.github_token, 
        request.namespace, 
        current_user.username,
        request.incremental
    )
    
    mode_text = "Incremental Update" if request.incremental else "Full Load"
    return {"status": "success", "message": f"à¹€à¸£à¸´à¹ˆà¸¡à¸à¸£à¸°à¸šà¸§à¸™à¸à¸²à¸£ {mode_text} à¹à¸¥à¹‰à¸§!"}


# --- ğŸ› ï¸ Debug / Reset DB API ---
@app.get("/debug/init-db")
async def init_database_endpoint(db: Session = Depends(get_db)):
    try:
        print("ğŸš€ Resetting Database via API...")
        Base.metadata.drop_all(bind=engine)
        Base.metadata.create_all(bind=engine)

        users_data = [
            ("manager_seaside", "1234", "hotel-seaside"),
            ("manager_city", "1234", "hotel-city"),
            ("admin", "admin", "global")
        ]
        
        created_users = []
        for username, pwd, ns in users_data:
            new_user = UserModel(
                username=username,
                hashed_password=get_password_hash(pwd),
                client_id=ns,
                full_name=username 
            )
            db.add(new_user)
            created_users.append(username)
        
        db.commit()
        
        return {
            "status": "success", 
            "message": "ğŸ‰ Database Reset & Initialized Successfully!", 
            "users_created": created_users
        }

    except Exception as e:
        print(f"âŒ Error: {e}")
        return {"status": "error", "message": str(e)}
    
    

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)