from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import OAuth2PasswordRequestForm
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy import desc
import os
import uvicorn
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from pathlib import Path

# Import ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏∞‡∏ö‡∏ö
from .database import Base, engine
# ‚úÖ Import ChatHistory ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
from .auth import get_db, create_access_token, get_current_user, User as UserModel, ChatHistory

# ‡πÇ‡∏´‡∏•‡∏î ENV
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô Database (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ) ---
# ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á chat_history ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô
Base.metadata.create_all(bind=engine)

# --- Config ---
INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "docscarmencloud")

# --- ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏°‡∏≠‡∏á AI ---
print("üß† Loading AI Brain...")
try:
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)
    llm = ChatGoogleGenerativeAI(model="gemma-3-27b-it", temperature=0.3)
    
    prompt_template = """
    Role: You are "Carmen" (‡∏Ñ‡∏≤‡∏£‡πå‡πÄ‡∏°‡∏ô), a professional and gentle AI Assistant for Carmen Software.
    
    Instructions:
    1. Answer the question based ONLY on the provided context.
    2. **Tone:** Be polite, helpful, and professional.
    3. **Language Rules:**
       - If the user asks in **Thai**: Answer in **Thai** and MUST use female polite particles (e.g., ‡∏Ñ‡πà‡∏∞, ‡∏Ñ‡∏∞, ‡∏ô‡∏∞‡∏Ñ‡∏∞).
       - If the user asks in **English** or explicitly requests English: Answer in **English**.
    
    Context Information:
    {context}
    
    User Question: {question}
    
    Answer:
    """
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
except Exception as e:
    print(f"‚ùå AI Init Error: {e}")
    vectorstore = None
    llm = None

# --- Setup FastAPI ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- üîê Login API ---
@app.post("/token")
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    user = db.query(UserModel).filter(UserModel.username == form_data.username).first()
    
    from passlib.context import CryptContext
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
    
    if not user or not pwd_context.verify(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer", "client_namespace": user.client_id}

# --- üìú API ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó (New Feature) ---
@app.get("/chat/history")
async def get_chat_history(
    current_user: UserModel = Depends(get_current_user), 
    db: Session = Depends(get_db)
):
    # ‡∏î‡∏∂‡∏á 50 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡∏Ç‡∏≠‡∏á User ‡∏Ñ‡∏ô‡∏ô‡∏µ‡πâ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏´‡∏°‡πà)
    history = db.query(ChatHistory).filter(ChatHistory.user_id == current_user.id)\
                .order_by(desc(ChatHistory.timestamp))\
                .limit(50).all()
    
    # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏î‡∏∂‡∏á‡πÅ‡∏ö‡∏ö desc (‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤) ‡πÄ‡∏û‡∏∑‡πà‡∏≠ limit ‡πÅ‡∏ï‡πà‡∏ï‡∏≠‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏´‡∏°‡πà
    return history[::-1] 

# --- üí¨ Chat API (Save History) ---
class Question(BaseModel):
    text: str

# ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå backend/api.py

# 1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Chat Endpoint ‡πÄ‡∏î‡∏¥‡∏° (‡πÉ‡∏´‡πâ return id)
@app.post("/chat")
async def chat_endpoint(
    question: Question, 
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if not vectorstore: raise HTTPException(status_code=500, detail="AI Not Ready")
    
    try:
        user_message = question.text
        
        # Save User Msg
        user_msg_db = ChatHistory(user_id=current_user.id, sender="user", message=user_message)
        db.add(user_msg_db)
        db.commit()
        
        # ... (‡∏™‡πà‡∏ß‡∏ô AI Search & Generate ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡∏ú‡∏°‡∏Ç‡∏≠‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô Search ‡πÑ‡∏ß‡πâ (‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
        # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏Ç‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏à‡πÅ‡∏Å‡πâ ‡πÅ‡∏õ‡∏∞‡∏ó‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Logic ‡πÄ‡∏ï‡πá‡∏°‡πÜ ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö
        
        # --- Logic AI (‡∏¢‡πà‡∏≠) ---
        client_ns = current_user.client_id 
        docs_private = []
        if client_ns and client_ns != "global":
            docs_private = vectorstore.similarity_search(user_message, k=2, namespace=client_ns)
        docs_common = vectorstore.similarity_search(user_message, k=2, namespace="") 
        all_docs = docs_private + docs_common

        if not all_docs:
            bot_ans = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞"
        else:
            chain = PROMPT | llm | StrOutputParser()
            context_text = "\n\n".join([d.page_content for d in all_docs])
            bot_ans = chain.invoke({"context": context_text, "question": user_message})
        # ---------------------

        # Save Bot Msg
        bot_msg_db = ChatHistory(user_id=current_user.id, sender="bot", message=bot_ans)
        db.add(bot_msg_db)
        db.commit() # Commit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ ID
        db.refresh(bot_msg_db) # ‡∏î‡∏∂‡∏á ID ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤

        # ‚úÖ Return ID ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!)
        return {
            "answer": bot_ans, 
            "message_id": bot_msg_db.id 
        }

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model ‡πÅ‡∏•‡∏∞ API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Feedback (‡πÉ‡∏´‡∏°‡πà ‚ú®)
class FeedbackRequest(BaseModel):
    score: int # 1 = Like, -1 = Dislike

@app.post("/chat/feedback/{message_id}")
async def feedback_endpoint(
    message_id: int,
    feedback: FeedbackRequest,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô DB
    msg = db.query(ChatHistory).filter(ChatHistory.id == message_id).first()
    
    if not msg:
        raise HTTPException(status_code=404, detail="Message not found")
        
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á User ‡∏Ñ‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏° (‡∏Å‡∏±‡∏ô‡∏°‡∏±‡πà‡∏ß)
    if msg.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not your message")

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
    msg.feedback = feedback.score
    db.commit()
    
    return {"status": "success", "score": feedback.score}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)