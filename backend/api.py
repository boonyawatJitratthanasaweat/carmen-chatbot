from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import OAuth2PasswordRequestForm
from pydantic import BaseModel
from sqlalchemy.orm import Session
import os
import uvicorn
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from pathlib import Path

# Import ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏∞‡∏ö‡∏ö
from .database import Base, engine
# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏•‡∏ö authenticate_user_func ‡∏≠‡∏≠‡∏Å‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÅ‡∏Å‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
from .auth import get_db, create_access_token, get_current_user, User as UserModel

# ‡πÇ‡∏´‡∏•‡∏î ENV
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# --- Config ---
INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "docscarmencloud")

# --- ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏°‡∏≠‡∏á AI ---
print("üß† Loading AI Brain...")
try:
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)
    llm = ChatGoogleGenerativeAI(model="gemma-3-27b-it", temperature=0.3)
    
    prompt_template = """
    "You are a helpful female assistant named Carmen."
    ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Context ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô
    
    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {context}
    
    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
    ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):
    """
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
except Exception as e:
    print(f"‚ùå AI Init Error: {e}")
    vectorstore = None
    llm = None

# --- Setup FastAPI ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- üîê Login API ---
@app.post("/token")
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    user = db.query(UserModel).filter(UserModel.username == form_data.username).first()
    
    # Import passlib ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢
    from passlib.context import CryptContext
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
    
    if not user or not pwd_context.verify(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer", "client_namespace": user.client_id}

# --- üí¨ Chat API (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ 2 ‡∏ó‡∏≤‡∏á) ---
class Question(BaseModel):
    text: str

@app.post("/chat")
async def chat_endpoint(
    question: Question, 
    current_user: UserModel = Depends(get_current_user)
):
    if not vectorstore: raise HTTPException(status_code=500, detail="AI Not Ready")
    
    try:
        user_message = question.text
        client_ns = current_user.client_id 
        
        print(f"User: {current_user.username} | Private NS: {client_ns} | Searching Both...")

        # ‚úÖ 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (Private Knowledge)
        docs_private = []
        if client_ns and client_ns != "global":
            # ‡∏´‡∏≤ 2 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
            docs_private = vectorstore.similarity_search(user_message, k=2, namespace=client_ns)

        # ‚úÖ 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Å‡∏•‡∏≤‡∏á (Common/Default Knowledge)
        # ‡πÉ‡∏ô Pinecone ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏∑‡∏≠ namespace="" (‡∏ß‡πà‡∏≤‡∏á) ‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ô‡πÉ‡∏ä‡πâ "global"
        # ‡πÅ‡∏ï‡πà user ‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ namespace "__default__" ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏µ‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô namespace="__default__"
        # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ Default ‡∏Ç‡∏≠‡∏á Pinecone ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ "" (String ‡∏ß‡πà‡∏≤‡∏á) ‡∏Ñ‡∏£‡∏±‡∏ö
        
        docs_global = vectorstore.similarity_search(user_message, k=2, namespace="") 
        
        # ‚úÖ 3. ‡∏°‡∏±‡∏î‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Merge)
        # ‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô + ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏•‡∏≤‡∏á
        all_docs = docs_private + docs_global

        if not all_docs:
            return {"answer": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡πà‡∏∞"}

        # ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏°‡∏≠‡∏á AI
        chain = PROMPT | llm | StrOutputParser()
        context_text = "\n\n".join([d.page_content for d in all_docs])
        
        response = chain.invoke({"context": context_text, "question": user_message})
        
        return {"answer": response}

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)