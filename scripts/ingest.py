import os
import time
from github import Github
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore

# --- 1. ‡πÉ‡∏™‡πà Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≤‡∏Å .env ---
from dotenv import load_dotenv
load_dotenv()

os.environ["GITHUB_TOKEN"] = os.getenv("GITHUB_TOKEN", "")
os.environ["PINECONE_API_KEY"] = os.getenv("PINECONE_API_KEY", "")  
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY", "")   

INDEX_NAME = "docscarmencloud"
REPO_NAME = "llHorizonll/docscarmencloud"

def get_github_docs(repo_name, access_token):
    print(f"   ...‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Repo: {repo_name}")
    docs = []
    g = Github(access_token)
    repo = g.get_repo(repo_name)
    contents = repo.get_contents("")
    
    while contents:
        file_content = contents.pop(0)
        if file_content.type == "dir":
            contents.extend(repo.get_contents(file_content.path))
        else:
            if file_content.path.endswith((".md", ".mdx")):
                try:
                    decoded_content = file_content.decoded_content.decode("utf-8")
                    docs.append(Document(
                        page_content=decoded_content,
                        metadata={"source": file_content.html_url}
                    ))
                except Exception:
                    pass
    return docs

def main():
    print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô Full Load (Model: text-embedding-004)... ")
    print("‚è≥ ‡∏£‡∏≠ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°...")
    time.sleep(10)

    docs = get_github_docs(REPO_NAME, os.environ["GITHUB_TOKEN"])
    if not docs:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡∏¢!")
        return

    print("‚úÇÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏±‡πà‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(docs)
    print(f"   -> ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(chunks)} ‡∏ä‡∏¥‡πâ‡∏ô (Chunks)")

    print(f"‚òÅÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏¢‡∏≠‡∏¢‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô Pinecone...")
    
    # ‚úÖ ‡πÉ‡∏ä‡πâ Model ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)

    # --- ‡∏™‡∏π‡∏ï‡∏£ Safe Mode (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞) ---
    batch_size = 30  # ‡∏™‡πà‡∏á‡∏ó‡∏µ‡∏•‡∏∞ 30 ‡∏ä‡∏¥‡πâ‡∏ô
    sleep_time = 20  # ‡∏û‡∏±‡∏Å 20 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
    
    total_chunks = len(chunks)
    
    for i in range(0, total_chunks, batch_size):
        batch = chunks[i : i + batch_size]
        print(f"   üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà {i // batch_size + 1} (Process: {i}/{total_chunks})...")
        
        success = False
        retries = 0
        
        while not success and retries < 3:
            try:
                vectorstore.add_documents(batch)
                success = True
                print(f"      ‚úÖ ‡∏ú‡πà‡∏≤‡∏ô! ‡∏û‡∏±‡∏Å‡∏´‡∏≤‡∏¢‡πÉ‡∏à {sleep_time} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...")
                time.sleep(sleep_time) 
            except Exception as e:
                retries += 1
                print(f"      ‚ö†Ô∏è ‡∏ä‡∏ô Limit! (Error 429) -> ‡∏£‡∏≠ 60 ‡∏ß‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {retries})")
                time.sleep(60) 
        
        if not success:
            print("      ‚ùå ‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô (Error ‡∏ã‡πâ‡∏≥ 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)")
    
    print("üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß")

if __name__ == "__main__":
    main()